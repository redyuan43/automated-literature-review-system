

Manuscript received 28 June 2022; revised 22 September 2022; accepted 23 October 2022. Date of publication 26 October 2022; date of current version 3 February 2023. _(Corresponding author: Bappaditya Dey)_.




Color versions of one or more figures in this article are available at [https://doi.org/10.1109/TSM.2022.3217326](https://doi.org/10.1109/TSM.2022.3217326)

## I Introduction

Moore's Law states that transistor density will double every two years, which is still upheld until today, thanks to the constant innovations in the semiconductor industry. Advance technologies such as extreme ultraviolet (EUV) lithography and multiple patterning techniques [1, 2] are the driving forces to keep extending Moore's Law, as well as leading the whole industry moving towards 3 nm node and beyond. In these patterning schemes, especially in multi-patterning processes, placement error control between two process layers is strictly required to maintain high yield and performance [3, 4], and the most important metrics to evaluate placement error is EPE. EPE can be defined as the relative displacement of the edges of features from their intended target location, and it is a directly representation of the pattern fidelity of fabricated structures. EPE is the combination of overlay errors and CD errors including OPC and stochastics [5]. The visualization of EPE and the distribution budget of its components are described in Fig. 1.

In [6], Mulkens et al. proposed an analytical method to calculate the EPE, which is shown in (1). Here in this equation, \(\textit{Hal}\textit{Range}_{\textit{OPC}}\) is the half-range of the CD error due to optical proximity residuals. The second term \(\sigma_{\textit{PBA}}\) stands for proximity bias average error, which is the feature-specific field average CD induced by scanner tool-to-tool variance. The third term, \(\sigma_{\textit{LWR}}\), refers to line width roughness, which is local errors that come from resist and photon stochastics in lithography process. The two terms inside the square root are the global errors of EPE. Overlay error (\(\sigma_{\textit{overlap}}\)) is the placement shift error of the printed patterns, while \(\sigma_{\textit{CDU}}\) is the CD uniformity that originates from etch and deposition steps.

\[\textit{EPE}_{\textit{max}} =\frac{\textit{Hal}\textit{Range}_{\textit{OPC}}}{2}+\frac{3 \sigma_{\textit{PBA}}}{2}+\frac{6\sigma_{\textit{LWR}}}{\sqrt{2}}\] \[\quad+\sqrt{\left(3\sigma_{\textit{overlap}}\right)^{2}+\left( \frac{3\sigma_{\textit{CDU}}}{2}\right)^{2}} \tag{1}\]

EPE is the main challenge that inhibits the continuation of devices' size shrinkage in semiconductor industry. Without good value of the EPE, pattern-to-pattern electrical contacts can be poor, which would lead to fatal failures of IC devices such as short circuits or broken connections. Therefore, it is essential to develop effective EPE analysis and control solutions to ensure proper functionality of fabricated semiconductor devices. As the EPE consists of both overlay and CD errors, this goal can only be achieved by optimizing both overlay metrology and control methods, as well as mask design computational techniques in lithography process. Fig. 2 illustrates the EPE optimization flow.

In modern measurement schemes, overlay is measured by metrology tools which detect and scan specific targets or marks on scribe lines and/or within the field of the product wafers [4, 8]. Typically, in the semiconductor industry, a sampling approach for overlay metrology is employed, in which only a subset of wafers in the production line are measured by physical tools such as KLA optical-based overlay or ASML YieldStar diffraction-based overlay. This method suffers from a major drawback that a lot of wafers are not measured to detect abnormal overlay signatures. As a result, there is a great chance that underqualified wafers are not detected and can slip through to the next process steps. This can causea serious problem in the later stages, since many dies will not yield, or wafers need to be scrapped [9]. One solution to tackle this problem is applying the virtual overlay metrology (VOM) method. There are tens of gigabytes of data generated every day from sensors in the lithography clusters and other processing equipment in a typical semiconductor plant [10]. This amount of available data can be utilized by applying machine learning techniques to build a model which can predict the overlay property of each wafer, without actually measuring the overlay by physical metrology tools. Machine learning based VOM models can also find and link specific root causes of abnormal overlay excursions, enabling software tools or operators to take corrective and/or preventive actions in timely manner [9, 11]. Machine learning can also be used to aid overlay metrology tools in order to improve their measurement accuracy and applied in control schemes in the fabrication process to reduce the overlay error.

Regarding the problem of reducing EPE in lithography process, mask synthesis optimization is one of the most crucial tasks, because it can help optimize both the placement errors and the critical dimension of the desired patterns. The conventional methods such as the rule-based [12, 13, 14] and model-based techniques [15, 16, 17] for mask synthesis have been applied for many years. Rule-based approaches are capable of achieving high performance on simple designs, but they are not able to handle complex target patterns. Whereas in contrast, the model-based approaches can produce great masks with high accuracy of printed patterns, but they are very time consuming and computationally expensive. To ensure accurate performance with good runtime, different machine learning based mask optimization methods have been introduced [18, 19, 20, 21]. One of these studies stated that a machine learning based model can approach a model-based method of a commercial software in terms of EPE performance but can produce the result up to 144 times faster [21]. This shows a great potential of machine learning in addressing mask optimization problems.

In this paper, a systematic review of applications based on machine learning techniques for the purposes of enhancing virtual overlay metrology, reducing overlay error, and improving mask optimization methods for EPE reduction was conducted. We also thoroughly discussed the objectives, datasets, input features, models, key findings, and limitations of the work in the literature. Finally, future work in machine learning based techniques for EPE analysis and optimization is suggested.

## II Methodology

In this review, the Preferred Reporting Elements for Systematic Reviews and Meta-Analyses (PRISMA) guidelines

Fig. 1: EPE visualization and its distribution budget for 5â€“7-nm logic node [5].

Fig. 2: EPE optimization flow [7].

was followed [22]. The reviewed papers were indexed in Google Scholar database, and the keywords for the queries were: 1. overlay, 2. mask optimization, 3. SRAF, 4. OPC, 5. analysis, 6. optimization, 7. metrology, 8. semiconductor, 9. machine learning, and 10. deep learning. In the search phrases, truncation was applied to the words "analysis*" and 'optimization*" in order to seek for their variations or synonyms. Two search queries were used in this work, one was for overlay analysis and optimization, and the other was for EPE. They were constructed by using logical operators as follow: 1. for overlay analysis and optimization: (1) AND (5) AND (6) AND (7) AND (8) AND (9 OR 10), and 2. for mask optimization: (2) AND (3 OR 4) AND (8) AND (9 OR 10).

To filter the results returned from the search query, this review applied three inclusion and three exclusion criteria. The three inclusion criteria consist of: (i) articles published from 2010, (ii) peer-reviewed journal and conference publications, and (iii) articles that focused on machine learning based techniques for overlay - EPE analysis and optimization. The criteria used for exclusion included: (i) articles that did not propose new machine learning methods to analyze or optimize overlay - EPE, (ii) review or survey articles, (iii) articles that were not written in English.

## III Results

Using the queries described before, the results returned 2110 and 599 articles for overlay analysis and mask optimization, respectively. In the initial screening after applying the inclusion and exclusion criteria on the title and abstracts of these articles, 2027 papers for overlay and 542 papers for EPE were filtered out. Finally, by applying the inclusion and exclusion criteria on the full text of those papers, 19 overlay papers and 17 mask synthesis papers remained. The selecting procedure is illustrated in Fig. 3.

For the articles in the topic of overlay analysis and optimization, they can be grouped in three categories, which are: (i) virtual overlay metrology, (ii) improvement of overlay metrology accuracy, and (iii) control scheme to improve overlay in manufacturing process. In terms of mask optimization tasks for EPE optimization, the publications are divided into two groups: (i) sub-resolution assist feature insertion, and (ii) optical proximity correction. The detail of which article belongs to which category is shown in Table I. Additionally, in Table II and Table III, the information about the reviewed articles was summarized, including the discussion about: (i) the objectives, (ii) the dataset and/or input features, (iii) the machine learning models, (iv) the results and key findings, and (v) the limitations.

the performance in [23] was recorded as the best, with the correlation of predicted and measured overlay R-squared value of 0.8321. The authors of that work used an approach called time series NARX with the fitting function shown by (2), where _u(t)_ is the input signal (sensors data and input context) at time t, _y(t)_ is the corresponding overlay prediction output at time t, _n\({}_{u}\)_ and _n\({}_{y}\)_ are the input and output sequence numbers, and _f_() is the approximation function that can be learnt by an ANN.

\[y(t)= f\ \left(u(t\ -\ n_{u}),\ldots,u(t\ -1),u(t),\right.\] \[\left.y(t\ -\ n_{y}),\ldots,\ \left.y(t\ -1)\right)\right) \tag{2}\]

Aside from the ANN based approach, the traditional machine learning models such as linear regression, t-SNE [9], PCA regression [25], Lasso regression, and Random Forest [26] have also been employed to solve the VM overlay problems. The predicted overlay performance (R-squared value) of those models varies from 0.65 to 0.80.

### _Overlay Metrology's Accuracy Improvement_

Applications of machine learning models in improving the accuracy of overlay metrology techniques have been successfully implemented in several studies. In [8], Gradient Boosting model was used to reduce the error in misregistration measurements of the optical overlay for after-develop inspection. Gradient Boosting is an ensemble machine learning model which takes the advantages of multiple weak Decision Tree predictors to obtain the strong one. Using this model, Verner et al. has improved the accuracy of the conventional imaging-based overlay measurement by 15% and 17% on gratings X and Y, respectively. The Gradient Boosting model was also used by Ophir et al. [32] to correct the TIS in optical overlay measurement, which is normally caused by the tool's interaction with target asymmetries, lens alignment, lens aberrations, and illumination alignment. The model developed in that work has reduced the mean of TIS for DRAM and NAND layers by 40% and 81%, respectively. Along with imaged-based overlay metrology, machine learning was also applied to improve the performance of the DBO measurement method. In [33], an ANN with Bayesian regularization model has been proposed to decrease the measurement inaccuracy caused by the sidewalls effect in the diffraction based overlay bottom gratings targets. Using the dose level of 500 mJ/s-cm2 for each pupil image, the overlay MSE of the proposed model reduced 42.22% compared to the conventional DBO model.

### _Control Scheme to Improve Overlay in Manufacturing Process_

To ensure high yield for the production line, the development of advanced overlay control scheme is very important.

Recently, machine learning models have been integrated in various process control steps to improve the wafers' overlay accuracy.

Run-to-run control is one of the most popular methods used in semiconductor industry, and it has been applied to optimize various process steps such as chemical-mechanicalplanarization (CMP) [52], chemical - vapor deposition [53], plasma etching reactor [54], and lithography process [55]. In [34], Overcast et al. has proposed several metrics with parametric clustering algorithms to identify which non-lithography processes (etch chambers, CMP processes, or high-temperature tools) significantly affect the overlay quality and stability. Once the notable non-lithography contexts have been detected, specific key numbers are calculated and fed to the run-to-run simulation software to check for the improvement of overlay performance. In [37], Kang et al. introduced another run-to-run control scheme which embeds with a regression VOM model to reduce overlay error of the photolithography process. In this control scheme, the VM models were first developed by experimenting different ML regression models to find the optimal one for each measurement position on wafer. Then, the output of these models will be fed into the EWMA controller, which adjusts the controllable input parameters so that the prediction matches the measurement. The authors have verified this run-to-run method in a Monte Carlo simulation, and the results showed a significant improvement compared to the system without the run-to-run controller.

As pointed out by Khakifirooz et al. [36], the lack of real-time metrology data is a major limitation of the run-to-run controller. Therefore, the authors have developed a dynamic control scheme which is able to compensate the overlay error in real time. In that study, the \(\epsilon\)-SVR optimization technique was used as the kernel for the online controller. \(\epsilon\)-SVR is a strong regression technique which is proved to be able to find the global minimum in the optimization problem and avoid overfitting. The proposed model made use of 10 variables including intra-field and inter-field overlay errors, as well as considered stochastic time delay of the process, which has successfully outperformed the conventional EWMA controller.

### _Challenges and Future Work_

As stated in [8], there are more than 1000 process steps to manufacture some leading-edge devices from a silicon wafer. In that process, a huge amount of data is generated by sensors from different tools. Thus, the biggest challenge in the field of machine learning based overlay analysis and optimization is to find which steps in the production line contribute the most to the overlay errors of a wafer. In other words, for the best performance of machine learning models, most relevant and significant features to train are crucial. Therefore, in the future, more advanced data analysis techniques need to be developed to identify which process steps have the most substantial impact on the overlay performance. From that, most meaningful features can be extracted from the data generated in those steps.

In addition, most of the reviewed studies above only considered the lithography-based processes in analyzing or optimizing overlay, while non-lithography-based processes also considerably contribute to the overlay performance of a wafer [34]. Hence, more work should be done to improve overlay outcome by combining data from both the lithography-based and non-lithography-based process steps.

Finally, many studies have trained their machine learning models with small datasets. This greatly limit the prediction accuracy of the models. For future work, machine learning models should be trained with larger datasets in order to improve their performance.

## V Discussion: Machine Learning Based Mask Optimization Techniques

With the rapid growth of machine learning field and the abundance of available data, various advanced models have been introduced to optimize the mask synthesis computation task in the semiconductor manufacturing process. Table III shows the summary results of 17 different studies about mask optimization techniques using machine learning.

### _Sub-Resolution Assist Feature Insertion (SRAF)_

Among mask optimization techniques, SRAF is one of the most effective approaches to enhance the through-process robustness of exposing masks in lithography process [56]. SRAFs are small features placed around the target patterns (Fig. 4) in order to create a region with high features density, which can improve the depth-of-focus of those desired patterns [58]. As a result, the resolution of the printed patterns when using mask assisted SRAFs is improved considerably compared to the masks without SRAFs.

Most of the reviewed studies in this survey used traditional ML models such as Logistic Regression (LGR) [38, 40], Support Vector Classification (SVC) [38], Supervised Online Dictionary Learning (SODL) [39], or Decision Tree [40] for the insertion of SRAFs. In those studies, each layout clip of training and testing patterns is divided into small pixels, and these pixels' feature vectors are sampled by using the Concentric Circle Area Sampling (CCAS) scheme. Then, all the pixels are classified using trained ML models to predict whether a pixel should be inserted as SRAF or not. The results in [38] indicate that the SVC-based model performed approximately 5% better than LGR-based model for EPE, while in [40], Xu et al. stated that LGR has better performance compared to Decision Tree. In [39], Geng et al. showed that EPE and PV band of the SODL-based model improved 3.5% and 11.8%, respectively, compared to the LGR-based model in [40]. In terms of the runtime, machine learning based models in those studies have achieved up to 10x speed increase compared to the model-based technique used in commercial software tools.

Besides traditional ML algorithms, modern Deep Learning algorithm has also been used for SRAFs insertion. In [21], Alawieh et al. introduced a SRAFs insertion framework which used Conditional Generative Adversarial Networks (CGANs) to generate SRAF features. Using CGAN, the model can be trained to translate images of original layout domain to the domain which has layout with SRAFs. The experimental results have shown that the CGAN-based model could achieve similar performance of the SVC-based model proposed in [38], but with around 14.6x speed increase in the runtime.

### _Optical Proximity Correction_

Light diffraction and interference are the main contributors to the distortion errors like rounded conners or shortened line-ends in photolithography process, especially in advanced technology nodes, where the critical dimensions are in the range of only several nanometers. To compensate for those errors and minimize the EPE, OPC is widely applied. Fig. 5 demonstrates the role of OPC in photolithography process.

In previous studies, several traditional ML models such as Nonparametric Kernel Regression [20, 46], Random Forest Regression [19], and Gradient Descent [45] have been introduced for OPC optimization. These models first fragment the edges of target patterns, then extract the features from the fragmented layout. Because the diffraction effects are extremely complicated toward the sub-resolution domain, the traditional ML models have immense complexity and often suffer from the overfitting issue [39, 59]. To overcome the overfitting problem, a hierarchical Bayes model (HBM) with CCAS

Fig. 4: Optimized lithographic masks with SRAFs and OPC patterns [40].

Fig. 5: The role of OPC in photolithography process [42].

sampling scheme has been proposed by Matsunawa et al. [42]. In that work, a generalized linear mixed model was trained while considering four different edge types, which are normal, convex, concave and line-end edge. The results from HBM model can be comparable to a 10-iteration conventional model-based method.

Recently, supervised deep learning techniques, including ANN [18, 47], CNN [48], RNN [49], ENN [50], and GAN [43] have been implemented with promising results. However, the limitation of supervised learning models is that they need a training dataset generated from other mask generation tools for training. Thus, their performance can hardly surpass the available tools' output. One solution for this was proposed by Liu in [44], where Reinforcement Learning with ANN was used for mask synthesis. This approach directly optimizes the mask based on the user's desired quality metrics with the rewarding-punishing mechanism. The proof-of-concept evaluation provided by the author has shown that Reinforcement Learning for mask optimization is a potential direction that can be explored in the future.

### _Challenges and Future Work_

Despite a great number of successful applications of ML techniques on mask synthesis and optimization, there are still some difficult challenges. For example, in SRAF insertion, each pixel in a layout clip is classified one by one. Since one clip normally has the width and height in micrometer scale, while the precision of SRAF features needs to be in the nanometer region, the number of pixels required can be enormous. This eventually becomes very computationally expensive, especially with complex ML models. One approach to deal with this issue in SRAF generation is to adapt end-to-end methods with an advance deep learning-based architecture such as GAN. GAN models can directly map the images of target patterns to that of the mask patterns, hence effectively reducing the computational power without compromising much accuracy.

The challenge of OPC optimization lies in the high complexity of diffraction and process effects, especially when the fabricated patterns are increasingly denser, while the sizes become smaller and smaller. Even the state-of-the-art models based OPC techniques are yet to be optimal to capture the physical phenomena. As most of the previous ML-based OPC models rely on the output from model-based OPC for training, this becomes a performance bottleneck for the further improvement of OPC techniques. Model-based OPC is heavily relied on lithography simulators which solve Maxwell's equations by using numerical methods such as finite differences and finite elements. Although these methods have proven to be generally accurate, they are very computationally expensive. Besides, their obtained solutions are discrete or have limited differentiability [60]. Furthermore, choosing optimal boundary conditions and fine-tuning the geometry for these discretizing approaches heavily rely on past experience of the design templates, and due to the constraints on computational power and time, only a small number of parameters are adjusted in order to find the desired responses [61]. Physics-informed ML [62] approaches can be a prospective direction to transcend the aforementioned limitations. Physics-informed ML is a type of ML methods which embed the physical laws governing the given dataset with a ML model. This ML method overcomes the low data availability problem and is very effective in solving ill-posed and inverse problems compared to conventional mesh-based solvers. Fig. 6 shows an illustration of a physics-informed ML algorithm. Here in this figure, the left part represents the conventional ML network, whose output is the surrogate solution of the physical model, whereas the right part contains the mathematical function of the physics prior. The loss function is the sum of supervised loss of the conventional ML network and the unsupervised loss of the physical model. The network is trained until the loss is smaller than a pre-determined/desired threshold \(\varepsilon_{0}\).

Physics-informed ML has been applied in various fields, such as geophysics [63, 64], molecular simulations [65], material sciences [66], and quantum chemistry [67]. In the domain of electromagnetism, Ref [68], and Ref [69] have successfully built wave-propagating simulators by leveraging physics-informed ML models, which integrate Maxwell's equations with neural networks. Applying these simulators in developing OPC and inverse lithography models is expected to be able to improve the performance of mask generation tasks in the future.

## VI Conclusion

In this paper, the recent advances of machine learning applications in EPE analysis and optimization problems in semiconductor manufacturing have been reviewed. ML models have proved to be beneficial in a number of tasks, including virtual overlay metrology, overlay metrology's accuracy improvement, overlay control scheme, SRAFs insertion, and OPC. Currently, there are a great number of ongoing studies with the effort of pushing further the effectiveness of Machine Learning models to reduce EPE and enable higher yield for the manufacturing process. This area of research will significantly contribute to the roadmap toward 3nm node of the semiconductor industry.

Nevertheless, applications of ML techniques in EPE analysis and optimization are still in the very early stage of development. There are a variety of challenges that are yet to be overcome, which offer a considerable scope for future research work.

Fig. 6: Illustration of a physics-informed ML algorithm [62].

