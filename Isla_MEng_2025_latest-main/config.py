# config.py - ç³»ç»Ÿé…ç½®æ–‡ä»¶

import os
from dataclasses import dataclass
from typing import Dict, Any

@dataclass
class OllamaConfig:
    """Ollamaé…ç½®ç±»"""
    host: str = "192.168.100.140"
    port: int = 11434
    base_url: str = None
    timeout: int = 300  # 5åˆ†é’Ÿè¶…æ—¶
    
    def __post_init__(self):
        if self.base_url is None:
            self.base_url = f"http://{self.host}:{self.port}"

@dataclass
class ModelConfig:
    """æ¨¡å‹é…ç½®ç±»"""
    # å°æ¨¡å‹æµ‹è¯•ç¯å¢ƒ
    small_model: str = "qwen3:30b-a3b-instruct-2507-q4_K_M"  # Agentä½¿ç”¨çš„å°æ¨¡å‹
    main_model: str = "qwen3:30b-a3b"  # ä¸»æ¨¡å‹
    test_model: str = "qwen3:30b-a3b"   # æµ‹è¯•ç”¨æ¨¡å‹
    
    # é’ˆå¯¹ä¸åŒä»»åŠ¡çš„ç‰¹æ®Šé…ç½® (ä»…åœ¨éœ€è¦æ—¶è¦†ç›–Ollamaé»˜è®¤å€¼)
    task_configs: Dict[str, Dict[str, Any]] = None
    
    def __post_init__(self):
        if self.task_configs is None:
            # åªè°ƒæ•´å…³é”®å‚æ•°ï¼Œå…¶ä»–ä½¿ç”¨Ollamaé»˜è®¤å€¼
            self.task_configs = {
                "literature_generation": {
                    "temperature": 0.3  # å­¦æœ¯å†…å®¹éœ€è¦æ›´å‡†ç¡®
                },
                "agent_review": {
                    "temperature": 0.5  # è¯„å®¡éœ€è¦å¹³è¡¡å‡†ç¡®æ€§å’Œåˆ›é€ æ€§
                },
                "chemical_analysis": {
                    "temperature": 0.2  # åŒ–å­¦åˆ†æéœ€è¦æœ€é«˜å‡†ç¡®æ€§
                },
                "diagram_generation": {
                    "temperature": 0.1,  # æ¦‚å¿µå›¾éœ€è¦ç»“æ„åŒ–æ€ç»´
                    "max_tokens": 4096   # å›¾è¡¨ä»£ç å¯èƒ½è¾ƒé•¿
                }
            }

@dataclass
class SystemConfig:
    """ç³»ç»Ÿé…ç½®ç±»"""
    # ç¯å¢ƒé…ç½®
    environment: str = "test"  # test | production
    debug: bool = True
    
    # æ–‡ä»¶è·¯å¾„
    input_dir: str = "./files_mmd"
    output_dir: str = "./outputs"
    embeddings_dir: str = "./embeddings"
    logs_dir: str = "./logs"
    
    # å¤„ç†å‚æ•°
    chunk_size: int = 1000
    chunk_overlap: int = 200
    max_concurrent_requests: int = 5
    
    # Agenté…ç½®
    max_agent_rounds: int = 10
    agent_timeout: int = 180
    
    # åŒ–å­¦å…¬å¼å¤„ç†
    preserve_formulas: bool = True
    formula_formats: list = None
    
    def __post_init__(self):
        if self.formula_formats is None:
            self.formula_formats = ["latex", "mathml", "unicode"]
        
        # æ ¹æ®ç¯å¢ƒè°ƒæ•´é…ç½®
        if self.environment == "production":
            self.debug = False
            self.max_concurrent_requests = 10

# å…¨å±€é…ç½®å®ä¾‹
OLLAMA_CONFIG = OllamaConfig()
MODEL_CONFIG = ModelConfig()
SYSTEM_CONFIG = SystemConfig()

# ç¯å¢ƒå˜é‡è¦†ç›–
def load_config_from_env():
    """ä»ç¯å¢ƒå˜é‡åŠ è½½é…ç½®"""
    
    # Ollamaé…ç½®
    if os.getenv("OLLAMA_HOST"):
        OLLAMA_CONFIG.host = os.getenv("OLLAMA_HOST")
    if os.getenv("OLLAMA_PORT"):
        OLLAMA_CONFIG.port = int(os.getenv("OLLAMA_PORT"))
    
    # æ¨¡å‹é…ç½®
    if os.getenv("MAIN_MODEL"):
        MODEL_CONFIG.main_model = os.getenv("MAIN_MODEL")
    if os.getenv("SMALL_MODEL"):
        MODEL_CONFIG.small_model = os.getenv("SMALL_MODEL")
    
    # ç³»ç»Ÿé…ç½®
    if os.getenv("ENVIRONMENT"):
        SYSTEM_CONFIG.environment = os.getenv("ENVIRONMENT")
    if os.getenv("DEBUG"):
        SYSTEM_CONFIG.debug = os.getenv("DEBUG").lower() == "true"
    
    # é‡æ–°è®¡ç®—ä¾èµ–é…ç½®
    OLLAMA_CONFIG.__post_init__()

# é…ç½®éªŒè¯
def validate_config():
    """éªŒè¯é…ç½®æœ‰æ•ˆæ€§"""
    import requests
    try:
        response = requests.get(f"{OLLAMA_CONFIG.base_url}/api/tags", timeout=5)
        if response.status_code == 200:
            print(f"âœ… Ollamaè¿æ¥æˆåŠŸ: {OLLAMA_CONFIG.base_url}")
            return True
        else:
            print(f"âŒ Ollamaè¿æ¥å¤±è´¥: HTTP {response.status_code}")
            return False
    except Exception as e:
        print(f"âŒ Ollamaè¿æ¥å¼‚å¸¸: {e}")
        return False

# åˆå§‹åŒ–é…ç½®
load_config_from_env()

if __name__ == "__main__":
    print("ğŸ”§ ç³»ç»Ÿé…ç½®ä¿¡æ¯:")
    print(f"OllamaæœåŠ¡å™¨: {OLLAMA_CONFIG.base_url}")
    print(f"ä¸»æ¨¡å‹: {MODEL_CONFIG.main_model}")
    print(f"å°æ¨¡å‹: {MODEL_CONFIG.small_model}")
    print(f"ç¯å¢ƒ: {SYSTEM_CONFIG.environment}")
    print(f"è°ƒè¯•æ¨¡å¼: {SYSTEM_CONFIG.debug}")
    
    # éªŒè¯è¿æ¥
    validate_config()