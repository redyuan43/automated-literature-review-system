# Technical Specification: step3.py

**Date:** 2025-04-26

## 1. File Overview

* **Purpose:** This script implements the third step of the report generation pipeline, focusing on the review and iterative improvement of the initial chapter drafts generated by `step2.py`. It utilizes the Autogen framework to orchestrate a multi-agent system where specialized agents (e.g., Technical Accuracy, Clarity, Structure, Fact Checking) review sections of a chapter, provide feedback, and a Moderator agent consolidates this feedback. The script then attempts to rewrite the section based on the consolidated feedback using an external `rewrite_text` function (likely leveraging Gemma 27B). It includes logic for selectively applying reviews based on initial quality assessments and evaluating the improvements made.
* **Role in Project:** Consumes the JSON chapter data from `./initial_chapters/` (output of `step2.py`), orchestrates an agent-based review and rewrite process, evaluates the changes, and saves the improved chapter content (both as JSON and Markdown) into `./outputs/` and `./chapter_markdowns/` respectively. It also leverages evaluation functions from `final_evaluation.py` and rewrite capabilities from `rewrite_function.py`.

## 2. Key Classes

* **`CustomGemmaClient` (Extended):**
  * **Responsibility:** (Imported from `rewrite_function.py`) Provides the Autogen-compatible interface to the local Gemma LLM. This script adds a `cleanup` class method to release GPU resources.
* **`DebateManager`:**
  * **Responsibility:** A simple container to collect reviews from different agents during a "debate" phase (though the primary flow seems more sequential review -> moderation -> rewrite).
  * **Key Methods:** `add_review`, `resolve` (combines collected reviews).
  * **Core Functionality:** Facilitates gathering multiple agent perspectives before potential consolidation.
* **`TechnicalAccuracyAgent(autogen.AssistantAgent)`:**
  * **Responsibility:** Reviews a text section specifically for technical accuracy, factual correctness, and depth.
  * **Key Methods:** `__init__` (sets system message, registers `CustomGemmaClient`), `review` (generates prompt, runs chat, extracts improvement suggestions).
  * **Core Functionality:** Acts as an Autogen agent focused on technical content quality, providing feedback in a specific numbered list format between `***` markers.
* **`ClarityAgent(autogen.AssistantAgent)`:**
  * **Responsibility:** Reviews a text section for clarity, readability, flow, and sentence structure.
  * **Key Methods:** `__init__` (sets system message, registers `CustomGemmaClient`), `review` (generates prompt, runs chat, extracts improvement suggestions).
  * **Core Functionality:** Similar to `TechnicalAccuracyAgent` but focused on writing style and comprehensibility, providing feedback in the same `***`-delimited format.
* **`StructureAgent(autogen.AssistantAgent)`:**
  * **Responsibility:** Reviews a text section for logical organization, coherence, section flow, and overall structure.
  * **Key Methods:** `__init__` (sets system message, registers `CustomGemmaClient`), `review` (generates prompt, runs chat, extracts improvement suggestions).
  * **Core Functionality:** Focuses on the high-level organization of the text, providing feedback in the `***`-delimited format.
* **`ModeratorAgent(autogen.AssistantAgent)`:**
  * **Responsibility:** Consolidates feedback from multiple review agents, resolves conflicts (implicitly, by synthesizing), and produces a final, unified list of prioritized improvements.
  * **Key Methods:** `__init__` (sets system message, registers `CustomGemmaClient`), `review` (takes section and multiple reviews, generates prompt, runs chat, extracts consolidated improvements).
  * **Core Functionality:** Acts as the central point for synthesizing feedback before the rewrite step, providing output in the `***`-delimited format.
* **`FactCheckingAgent(autogen.AssistantAgent)`:**
  * **Responsibility:** Reviews a section specifically for citation accuracy and factual claims, comparing them against the provided `referenced_papers`.
  * **Key Methods:** `__init__` (sets system message, registers `CustomGemmaClient`), `review` (takes section and references, generates prompt, runs chat, extracts findings).
  * **Core Functionality:** Focuses on verifying claims and the correctness of citations based on the source material context provided, outputting findings (likely as text).

## 3. Key Functions

* **`setup_logging()`**: Configures file and stream logging for the script execution.
* **`cleanup_shared_model(cls)`**: Class method added to `CustomGemmaClient` to release GPU memory.
* **`extract_json_from_response(response: str)`**: Utility to robustly extract JSON content from potentially messy LLM string responses.
* **`save_consolidated_output(data: Dict, section_name: str)`**: Saves the final, improved section content and associated metadata (original text, reviews, improvements, quality scores) to a JSON file within `./outputs/consolidated/{chapter_num}/`.
* **`rewrite_section(section_text: str, improvements: List[str], model_config: Dict)`**: Placeholder/Wrapper function. The actual rewriting seems delegated to `rewrite_text` imported from `rewrite_function.py`. This function might prepare inputs or handle outputs specifically for the `step3` context.
* **`assess_quality(improved_text: str, original_text: str, referenced_papers: Dict = None, full_report_context: str = None)`**: Evaluates the quality of the text (original and improved) using metrics imported from `final_evaluation.py` (technical depth, clarity, structure, citation accuracy). Returns a dictionary of scores.
* **`extract_last_asterisk_section(text: str)`**: Utility to extract the content between the last pair of `***` markers in agent responses.
* **`parse_improvement_points(text: str)`**: Parses the numbered list of improvements from the `***`-delimited agent feedback string.
* **`get_moderator_improvements(review_results: Dict)`**: Extracts the consolidated improvement list from the `ModeratorAgent`'s response.
* **`get_needed_agents(metric_results: Dict[str, bool])`**: Determines which review agents are needed based on which initial quality metrics fall below predefined thresholds (logic in `check_metric_thresholds`).
* **`check_metric_thresholds(metrics: Dict)`**: Compares calculated quality metrics against hardcoded thresholds to decide if specific aspects (technical, clarity, structure, citation) need review. Returns a boolean dictionary.
* **`selective_review_section(section_name: str, section_content: str, needed_agents: List[str], referenced_papers: Dict = None, previous_citation_scores: Dict = None)`**: Orchestrates the review process for a single section. It invokes the required agents (determined by `get_needed_agents`), collects their reviews, calls the `ModeratorAgent` to consolidate, calls `rewrite_text` (via `rewrite_function.py`) to apply improvements, assesses the quality of the rewritten text, and returns the results. Handles potential errors during the process.
* **`get_all_chapter_files()`**: Finds all `chapter_*.json` files in the `./initial_chapters/` directory.
* **`create_chapter_markdown(chapter_number: int, sections: dict, consolidated_outputs: dict)`**: Generates a final Markdown report for a chapter by combining the improved sections and adding metadata/references. Saves it to `./chapter_markdowns/`.
* **`main()`**: The main execution function.
  * Sets up logging, environment variables, and loads model configurations.
  * Loads the shared Gemma model using `load_shared_model` from `rewrite_function.py`.
  * Iterates through each chapter file found by `get_all_chapter_files`.
  * For each chapter:
    * Loads the chapter data (JSON).
    * Initializes dictionaries to store results (`consolidated_outputs`, `quality_assessments`).
    * Performs an initial quality assessment of all sections using `assess_quality`.
    * Iterates through each section ("Background", "Current Research", "Recommendations"):
      * Checks initial metrics using `check_metric_thresholds`.
      * Determines needed agents using `get_needed_agents`.
      * If improvements are needed, calls `selective_review_section` to run the review/rewrite/assessment loop.
      * Stores the results and potentially improved section content.
      * Calls `save_consolidated_output` to save detailed results for the section.
      * Manages GPU memory using `CustomGemmaClient.cleanup()`.
    * Generates the final Markdown chapter file using `create_chapter_markdown`.
    * Logs completion and saves final quality assessments for the chapter.
  * Logs overall completion.

## 4. Data Structures / Constants

* **Input Data Structure:** Reads JSON files (output of `step2.py`) from `./initial_chapters/`. Each file represents a chapter and contains `question`, `domain`, `timestamp`, `sections` (dict of section names to content), `referenced_papers`, and `metadata`.
* **Output Data Structure:**
  * Saves detailed JSON output for each reviewed section in `./outputs/consolidated/{chapter_num}/{section_name}.json`. This includes original text, agent reviews, moderator improvements, rewritten text, and quality scores (before/after).
  * Saves final chapter content as Markdown files in `./chapter_markdowns/chapter_{chapter_num}.md`.
  * Saves final quality assessment scores for the chapter in `./outputs/final_quality_assessment_chapter_{chapter_num}.json`.
* **Constants:** File paths (`./initial_chapters/`, `./outputs/`, `./chapter_markdowns/`, `./logs/`), agent names, system messages/prompts for agents, quality metric thresholds (within `check_metric_thresholds`).
* **Agent Configuration:** `llm_config` derived from the `OAI_CONFIG_LIST` environment variable, specifying the use of `CustomGemmaClient` and generation parameters.

## 5. Logic Flow & Control

* Script execution starts in `main()`.
* Initial setup: Logging, environment vars, HuggingFace login, load shared LLM.
* Main loop iterates through chapter files found in `./initial_chapters/`.
* Inside the chapter loop:
  * Load chapter JSON data.
  * Perform initial quality assessment on all sections.
  * Inner loop iterates through specific sections ("Background", "Current Research", "Recommendations").
    * Check if initial quality metrics meet thresholds.
    * If not, identify which agents are needed based on failed metrics.
    * Call `selective_review_section`:
      * Instantiate and call the required review agents (`TechnicalAccuracyAgent`, `ClarityAgent`, `StructureAgent`, `FactCheckingAgent`).
      * Call `ModeratorAgent` to consolidate feedback.
      * Parse improvements.
      * Call `rewrite_text` (from `rewrite_function.py`) to generate improved text.
      * Call `assess_quality` again on the improved text.
      * Return results (improved text, reviews, scores).
    * Update the chapter data with the improved section content if rewriting occurred.
    * Save detailed section results using `save_consolidated_output`.
    * Clean up GPU memory.
  * After processing all sections, generate the final Markdown chapter using `create_chapter_markdown`.
  * Save final quality scores for the chapter.
* Error handling (try-except blocks) is present in `main` loop, `selective_review_section`, and utility functions like `extract_json_from_response`.
* Control flow heavily relies on conditional checks based on quality metrics (`check_metric_thresholds`, `get_needed_agents`) to determine whether to run the review/rewrite process for a section.

## 6. External Interactions

* **Imports:** `autogen`, `typing`, `json`, `os`, `torch`, `transformers`, `functools`, `huggingface_hub`, `pathlib`, `time`, `types`, `dotenv`, `re`, `logging`, `gc`, `traceback`. Also imports from local files: `final_evaluation` (evaluation metrics), `rewrite_function` (`rewrite_text`, `load_shared_model`, `CustomGemmaClient`).
* **File System Reads:**
  * `.env` file.
  * Chapter JSON files from `./initial_chapters/`.
* **File System Writes:**
  * Log files to `./logs/`.
  * Consolidated section output JSON files to `./outputs/consolidated/{chapter_num}/`.
  * Final quality assessment JSON files to `./outputs/`.
  * Final chapter Markdown files to `./chapter_markdowns/`.
* **External Libraries Called:**
  * `autogen`: Core library for defining and running agents/chats (`AssistantAgent`, `initiate_chat`).
  * `transformers`/`torch`: Used indirectly via `CustomGemmaClient` (from `rewrite_function.py`) for LLM loading and inference, and directly for GPU memory management (`cuda.empty_cache`).
  * `huggingface_hub`: For authentication (`login`).
  * `dotenv`: Loading `.env`.
  * `json`: Loading/saving data.
  * `re`: Parsing agent responses.
  * `logging`: Recording execution details.
* **Local Modules Called:**
  * `final_evaluation`: Functions like `calculate_technical_depth`, `calculate_clarity`, `calculate_structure`, `evaluate_citation_accuracy`.
  * `rewrite_function`: Functions `rewrite_text`, `load_shared_model`, and class `CustomGemmaClient`.
* **Exports/Intended Use by Others:** The primary outputs are the improved chapter files (JSON details in `./outputs/`, final Markdown in `./chapter_markdowns/`), likely intended for final compilation or review (`step4.py`?). The agents and review functions could potentially be reused, but the script is structured as a self-contained step.

## 7. Assumptions / Dependencies

* **Prior Steps:** Assumes `step1.py` and `step2.py` have run successfully, producing the FAISS index (used indirectly by `rewrite_text` if it needs context?) and the initial chapter JSON files in `./initial_chapters/`.
* **Environment:** Assumes a Python environment matching `environment.yml` is active. Requires `autogen`, `transformers`, `torch` (with CUDA), `huggingface_hub`, `dotenv`, and dependencies specified in imported local modules (`final_evaluation`, `rewrite_function`).
* **Hardware:** Critically depends on a compatible NVIDIA GPU with sufficient VRAM for the Gemma 27B model (as loaded/used by `CustomGemmaClient` / `rewrite_function`).
* **API Keys/Tokens:** Requires `HUGGINGFACE_TOKEN` for model access. `OAI_CONFIG_LIST` environment variable must be set correctly (pointing to `CustomGemmaClient`).
* **File Permissions:** Requires read access to `./initial_chapters/` and write access to `./outputs/`, `./chapter_markdowns/`, and `./logs/`.
* **Configuration:** Relies on environment variables, the structure of the input JSON files, and hardcoded thresholds/prompts within the script. Assumes the imported `rewrite_text` function behaves as expected.
